TODO:
- ..

LATER:
- add train report
- add world render
- add task with sparse reward
- build train report
- use dinamic learning rate
- batch normalization
- reward for exploration (see pappers..)


===============================================================

DONE:
+ passed PER test_world_10d
+ tested 5d-world
+ compared PER vs Uniform
+ tested ddpg_per with degree > 0
+ refactored train
+ fixed PER error -- add new samples
+ implemented PER prioritized expierence replay
+ fix expl in ddpg
+ used random target via task object
+ printed eval final state
+ fixed world.reset error
+ tested world 3d
+ print log after the time is recieved, use text.table - for logging rec, header
+ used 'with' with logger and timer -- test it as Sibscriber
+ printed train duration
+ evaluated during train
+ print if done
+ add experiments and make one
+ printed agent coords
+ removed .idea from git
+ project started
+ add to github
